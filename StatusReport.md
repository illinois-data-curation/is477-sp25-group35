## Project Goal
Our project goal has stayed the same. It is to determine the correlation between social media posts on reddit and stock market performance. Using two data sets from reddit and yahoo finance our plan is to analyze how reddit posts about stock market movement affect performance. 
## Completed Project Steps
Next, we are going to go through each task from our timeline that we have made progress on. First, our Github repository is up and running and our project plan was submitted on time. We then completed our data collection steps. We had planned to use the Reddit API to pull current data from Reddit, but due to licensing changes there is limited access without payment or early approval. Instead, we used a data set found on Kaggle that included the subreddits we planned to analyze against stock data. On the other hand, the Yahoo API worked perfectly; after finding the date times of the Reddit data we pulled the Yahoo Finance data from the same time periods focusing on five major tech companies: Apple, Amazon, Google, Microsoft, and Tesla. These companies are mentioned frequently on Reddit giving us more data to work with to determine correlation. After that, since we had finished our data acquisition step we moved to data cleaning. We built a unform schema to line up our Yahoo and Reddit data. We then cleaned the Reddit data by removing spam bot posts, removing duplicated, and, most importantly, filtering for our five companies of interest. This made our dataset a lot more manageable, but still there were too many posts to manually analyze. This leads into one of our biggest switches of the project, using a Python library called TextBlob. This library analyzes the Reddit posts through a sentiment analysis giving each post a positive, negative, or neutral value as well as a score from -1 to 1. This made this step a lot more efficient and better for future reproducibility. Throughout these sections of the project, we have learned to adjust to our plans because of the Reddit API issues and the sheer large number of Reddit posts. On the other hand, for our timeline we have been on track for most items. The hardest time constraint is our Snakemake workflow, but other than that we are right on time.
## Future Project Steps
We have completed a lot of the bulkier technical steps of the project so far. We have acquired our data, cleaned it, gathered Reddit post scores, and prepared it for analysis. Our next large step to work on is conducting a data analysis and creating visuals to display our findings. We are planning to make a graph to see the correlation between closing prices and how positive a Reddit post is. We will do this by utilizing matplotlib and seaborn Python libraires. After that, we will move on to the Snakemake setup to create a proper workflow. In the end, we will ensure our project meets all the requirements and being working on the final report.
## Project Artifacts and Repository Organization
As of now, our GitHub repository is organized and contains all the relevant files we’ve worked on up to this point. We’ve committed our data acquisition scripts, which include the code used to pull data from the Kaggle Reddit dataset to a condensed set as well as the Python scripts that utilize the yfinance library to pull stock data. These scripts are in the scripts/folder. We also have a data/ folder that holds our raw data as well as cleaned and filtered versions for both Reddit and Yahoo Finance. We will include a README file with basic documentation on how to run the scripts and what each file does. This makes it easier for someone else to understand our project setup if they wanted to reproduce our results. For sentiment analysis, we've committed the Jupyter Notebook where we used TextBlob to score the Reddit posts. The notebook has markdown cells explaining what's going on in the code at each step, along with example outputs from a few posts to show how sentiment is calculated. This file can be in the scripts/ directory. We plan on keeping our repository clean as we add more pieces, especially as we begin to build visualizations and set up our Snakemake workflow.
Now we're focused on producing visualizations. Those will be stored in the visuals/ folder in our GitHub repository. Once that's complete, we'll begin working on the Snakemake workflow, which should only take a week since we'll have to test it, so we know everything is functioning properly.
## Changes and Challenges
There have been a couple changes from the original plan. The biggest was switching from the Reddit API to the Kaggle dataset. This was because of new API limitations, but it worked out okay because the Kaggle data covered the same subreddits we were originally targeting. Another change was switching from manual sentiment tagging to using TextBlob. This adjustment saved us a lot of time and ended up really increasing consistency throughout the data, so ultimately it turned out better than our initial plan.
We also planned to analyze five technology companies. We did so after cleaning data and realizing that analyzing fewer companies would bring more in-depth information and more reliable analysis. They also have the highest mention counts in discussions on Reddit and are thus the most potential options for identifying patterns.
## Next Steps
Once the visualizations are complete, we will then begin connecting the pipeline with Snakemake. This will convert our data cleaning, analysis, and plotting scripts into a reproducible workflow. We will commit the final version to a new file called Snakefile.
Next, we will start creating the final report and making sure all of it is properly documented. This will be a summary of what we found, screenshots of our graphs, and some discussion on what the data means in terms of the connection between Reddit sentiment and stock price fluctuations. We will also consider what we would have done differently had we more time or if we could scale this up to larger data pools. If high correlation is found it could even help people predict market movement if they stay up to date on social media posts on Reddit or other platforms alike.